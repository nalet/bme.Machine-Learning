% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------

\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx} %This allows to include eps figures
\usepackage{subcaption}
\usepackage[section]{placeins}
\usepackage{layout}
\usepackage{etoolbox}
\usepackage{mathabx}
% This is to include code
\usepackage{listings}
\usepackage{xcolor}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstdefinestyle{Python}{
    language        = Python,
    basicstyle      = \ttfamily,
    keywordstyle    = \color{blue},
    keywordstyle    = [2] \color{teal}, % just to check that it works
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily
}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\begin{document}

% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------

%\renewcommand{\qedsymbol}{\filledbox}

\title{Review Assignment 1}%replace X with the appropriate number
\author{Nalet Meinen \\ %replace with your name
Machine Learning
}

\maketitle

\section{Linear algebra review}

\begin{enumerate}
    \item S = $\{v_1, ... , v_n\}$ be an orthogonal set of non-zero vectors in $\mathbb{R}^n$. Prove that the vectors in $S$ are linearly independent.

    \noindent\rule{\linewidth}{1pt}

    We assume a linear combination
    \begin{align*} 
        c_1 v_1 + c_2 v_2 + ... + c_k v_k = 0
    \end{align*}
    We want to show that
    \begin{align*} 
        c_1 = c_2 = ... = 0
    \end{align*}
    The dot product of $v_i$ for each $ i = 1,2, ... , k $:
    \begin{align*} 
        0 &= v_i \cdot 0 \\
          &= v_i \cdot (c_1 v_1 + c_2 v_2 + ... + c_k v_k) \\
          &= c_1 v_i \cdot v_1 + c_2 v_i \cdot v_2 + ... + c_k v_i \cdot v_k
    \end{align*}
    $S$ is an orthogonal set, we have $v_i \cdot v_j = 0 \, \textrm{if} \, i \neq j $, then we have:
    \begin{align*} 
        0 = c_i v_i \cdot v_i = c_i \|v_i\|^2
    \end{align*}
    $v_i$ is nonzero and length $\|v_i\|$ is nonzero, following that $c_i = 0$ \newline
    We conclude that $c_1 v_1 + c_2 v_2 + ... + c_k v_k = 0$ for every $ i = 1,2, ... , k $, so $S$ is \textbf{linearly independent}

    \item Given a square matrix $A \in \mathbb{R}^{n \times n}$ and a vector $x \in \mathbb{R}^n$ show that $x^\intercal Ax = x^\intercal ( \frac{1}{2} A + \frac{1}{2} A^\intercal )x$.
    
    \noindent\rule{\linewidth}{1pt}

    We assume that:

    \begin{align*} 
        A = 
        \begin{bmatrix}
            a_{11}    &   a_{12}    & \dots     &   a_{1n}    \\
            a_{21}    &   a_{22}    & \dots     &   a_{2n}    \\
            \vdots    &  \vdots     & \vdots    &   \vdots    \\   
            a_{m1}    &   a_{m2}    & \dots     &   a_{mn}    \\
        \end{bmatrix}
        x = 
        \begin{pmatrix}
            b_1     &
            b_2     &
            \dots  &
            b_m
        \end{pmatrix}
        \quad \emph{where} \, m = n
    \end{align*}

    The transposed values are:

    \begin{align*} 
        A^\intercal = 
        \begin{bmatrix}
            a_{11}    &   a_{21}    & \dots     &   a_{m1}    \\
            a_{12}    &   a_{22}    & \dots     &   a_{2n}    \\
            \vdots    &  \vdots     & \vdots    &   \vdots    \\   
            a_{1n}    &   a_{2n}    & \dots     &   a_{mn}    \\
        \end{bmatrix}
        x^\intercal = 
        \begin{pmatrix}
            b_1     &
            b_2     &
            \dots  &
            b_m
        \end{pmatrix}
    \end{align*}

    We want to show that this equation is true:
    \begin{align*} 
        x^\intercal Ax = x^\intercal ( \frac{1}{2} A + \frac{1}{2} A^\intercal )x
    \end{align*}

    If we insert the matrices:
    \begin{align*}
        \begin{pmatrix}
            b_1     &
            b_2     &
            \dots  &
            b_m
        \end{pmatrix} 
        \begin{bmatrix}
            a_{11}    &   a_{12}    & \dots     &   a_{1n}    \\
            a_{21}    &   a_{22}    & \dots     &   a_{2n}    \\
            \vdots    &  \vdots     & \vdots    &   \vdots    \\   
            a_{m1}    &   a_{m2}    & \dots     &   a_{mn}    \\
        \end{bmatrix}
        \begin{pmatrix}
            b_1     \\
            b_2     \\
            \dots  \\
            b_m
        \end{pmatrix}
        = \\
        \begin{pmatrix}
            b_1     &
            b_2     &
            \dots  &
            b_m
        \end{pmatrix} (\frac{1}{2} 
        \begin{bmatrix}
            a_{11}    &   a_{12}    & \dots     &   a_{1n}    \\
            a_{21}    &   a_{22}    & \dots     &   a_{2n}    \\
            \vdots    &  \vdots     & \vdots    &   \vdots    \\   
            a_{m1}    &   a_{m2}    & \dots     &   a_{mn}    \\
        \end{bmatrix}
         + \frac{1}{2}
        \begin{bmatrix}
            a_{11}    &   a_{21}    & \dots     &   a_{m1}    \\
            a_{12}    &   a_{22}    & \dots     &   a_{2n}    \\
            \vdots    &  \vdots     & \vdots    &   \vdots    \\   
            a_{1n}    &   a_{2n}    & \dots     &   a_{mn}    \\
        \end{bmatrix})
        \begin{pmatrix}
            b_1     \\
            b_2     \\
            \dots  \\
            b_m
        \end{pmatrix}
    \end{align*}

    Calculating in two steps:
    \begin{align*}
        ((a_{11} \cdot b_{1} + a_{21} \cdot b_{2} + a_{m1} \cdot b_{3}) \cdot b_{1} + (a_{12} \cdot b_{1} + a_{22} \cdot b_{2} \\
        + a_{32} \cdot b_{3}) \cdot b_{2} + (a_{1n} \cdot b_{1} + a_{2n} \cdot b_{2} + a_{mn} \cdot b_{3}) \cdot b_{3}) = \\
        \begin{pmatrix}
            b_1     &
            b_2     &
            \dots  &
            b_m
        \end{pmatrix} 
        (\begin{bmatrix}
            a_{11}                       &   \frac{a_{12} + a_{21}}{2}    & \dots     &   \frac{a_{1n} + a_{m1}}{2}   \\
            \frac{a_{12} + a_{21}}{2}    &   a_{22}                       & \dots     &   \frac{a_{12} + a_{21}}{2}   \\
            \vdots                       &   \vdots                       & \vdots    &   \vdots                      \\   
            \frac{a_{1n} + a_{m1}}{2}    &   \frac{a_{2n} + a_{32}}{2}    & \dots     &   a_{mn}                      \\
        \end{bmatrix})
        \begin{pmatrix}
            b_1     \\
            b_2     \\
            \dots  \\
            b_m
        \end{pmatrix}
    \end{align*}
    \begin{align*}
        ((a_{11} \cdot b_{1} + a_{21} \cdot b_{2} + a_{m1} \cdot b_{3}) \cdot b_{1} + (a_{12} \cdot b_{1} + a_{22} \cdot b_{2} \\
        + a_{32} \cdot b_{3}) \cdot b_{2} + (a_{1n} \cdot b_{1} + a_{2n} \cdot b_{2} + a_{mn} \cdot b_{3}) \cdot b_{3}) = \\
        (\frac{1}{2} \cdot (2 \cdot a_{11} \cdot b_{1} + (a_{12} + a_{21}) \cdot b_{2} + (a_{1n} + a_{m1}) \cdot b_{3}) \cdot b_{1} + \\
        \frac{1}{2} \cdot ((a_{12} + a_{21}) \cdot b_{1} + 2 \cdot a_{22} \cdot b_{2} + (a_{2n} + a_{32}) \cdot b_{3}) \cdot b_{2} + \\ 
        \frac{1}{2} \cdot ((a_{1n} + a_{m1}) \cdot b_{1} + (a_{2n} + a_{32}) \cdot b_{2} + 2 \cdot a_{mn} \cdot b_{3}) \cdot b_{3})
    \end{align*}

    \item Show that if $(A + B)^{-1} = A^{-1} + B^{-1}$ then $A B^{-1} A = B A^{-1} B$
    
    \noindent\rule{\linewidth}{1pt}

    \begin{align*}
                (A B^{-1} A )( B A^{-1} B ) &= I \, | \, \textrm{premultiply by} \, A^{-1} \\
         A^{-1} (A B^{-1} A )( B A^{-1} B ) &= A^{-1} I \\
               I ( B^{-1} A )( B A^{-1} B ) &= A^{-1} \\
                 ( B^{-1} A )( B A^{-1} B ) &= A^{-1} \, | \, \textrm{premultiply by} \, B \\
               B ( B^{-1} A )( B A^{-1} B ) &= B A^{-1} \\
                           A ( B A^{-1} B ) &= B A^{-1} \, \textrm{premultiply by} \, A^{-1} \\
                    A^{-1} A ( B A^{-1} B ) &= A^{-1} B A^{-1} \\
                                 B A^{-1} B &= A^{-1} B A^{-1}
    \end{align*}

    \item Use the definition of trace to show that $\textrm{tr}(A + B) = \textrm{tr}A + \textrm{tr}B$, where $A, B \in \mathbb{R}^{n \times n}$
    
    \noindent\rule{\linewidth}{1pt}

    \begin{align*}
        \textrm{tr}(A) &= \sum_{i=1}^{n} a_{ii} \quad \textrm{if} \, A = \textrm{squared matrix} \\
        \textrm{tr}(A + B) &\rightarrow \textrm{tr}(C) \\
        C &= 
        \begin{bmatrix}
            a_{11} + b_{11}  &   \dots            &   \dots            \\
            \dots            &   a_{22} + b_{22}  &   \dots            \\
            \vdots           &   \vdots           &   \vdots           \\   
            \dots            &   \dots            &   a_{nn} + b_{nn}  \\
        \end{bmatrix} \\
        \textrm{tr}(C) &= ( a_{11} + b_{11}  ) + ( a_{22} + b_{22} ) + ( \dots ) + ( a_{nn} + b_{nn}  ) \\
        \textrm{tr}(C) &= a_{11} + b_{11} + \dots +  a_{nn}  +  a_{22} + b_{22}  +  \dots   + b_{nn}   \\
        \textrm{tr}(C) &= ( a_{11} + b_{11} + \dots +  a_{nn} ) + ( a_{22} + b_{22}  +  \dots   + b_{nn} )   \\
        \textrm{tr}(C) &= \textrm{tr}(A) + \textrm{tr}(B)
    \end{align*}   

    \item Show that if $(\lambda_i, x_i)$ are the $i$-th eigenvalue and $i$-th eigenvector of a non-singular and symmetric matrix 
          $A \in \mathbb{R}^{n \times n}$, then $( \frac{1}{\lambda_i}, x_i)$ are the $i$-th eigenvalue and $i$-th eigenvector of $A^{_1}$.
          \textit{Hint: use the eigendecomposition of $A$}
    
    \noindent\rule{\linewidth}{1pt}

    \begin{align*}
        x_i y_i^\intercal = [x_i][y_i] = 
        \begin{bmatrix}
            x_1 y_1          &   x_1 y_2          &   \dots            \\
            x_2 y_1          &   \dots            &   \dots            \\
            \vdots           &   \vdots           &   \vdots            
        \end{bmatrix}
    \end{align*}
    
    For $A,B \in \mathbb{R}^{m \times n}$, $\textrm{rank}(A+B) \leq \textrm{rank}(A) + \textrm{rank}(B)$
    \begin{align*}
        \sum_{i=1}^m x_i - y_i^\intercal \leq m 
    \end{align*}   

    \item Show that $\textrm{rank}(A) \leq \textrm{min}\{m, n\}$, where $A, B \in \mathbb{R}^{m \times n}$
    
    \noindent\rule{\linewidth}{1pt}

    where $m$ corresponds to the number of rows and $n$ to the number of columns
    
    \begin{align*}
        \textrm{row-rank}(A) \leq m \quad \textbf{and} \quad  \textrm{column-rank}(A) \leq n \\
        \textrm{row-rank}(A) = \textrm{column-rank}(A) = \textrm{rank}(A) \leq n 
    \end{align*}     

    \item In each of the following cases, state whether the real matrix A is guaranteed to be singular or not. Justify your answer in each case.
    
    \begin{enumerate}

        \item  $A \in \mathbb{R}^{(n+1) \times n}$ is a full rank matrix.
        
        \noindent\rule{\linewidth}{1pt}

        A singular matrix is never a full-rank, because only if $\textrm{rank}(A) \leq \textrm{min}\{m,n\}$ is equal.

        \item $|A| = 0$.
        
        \noindent\rule{\linewidth}{1pt}

        When the determinant is zero, then the matrix is singular.

        \item $A$ is an orthogonal matrix.
        
        \noindent\rule{\linewidth}{1pt} 
        
        The transpose of an orthogonal matrix is equal to its inverse, hence this matrix is non-singular and invertible.

        \item $A$ has no eigenvalue equal to zero.
        
        \noindent\rule{\linewidth}{1pt}

        If a matrix has non-zero eigenvalues, then it is invertible.

        \item $A$ is a symmetric matrix with non-negative eigenvalues.
        
        \noindent\rule{\linewidth}{1pt}

        When all eigenvalues are positive a matrix is invertible.

    \end{enumerate}
    
\end{enumerate}    

\end{document}
